soft attention
===================

eta = 0.0003
lambda = 0.00001  overfits
[KILLED]

eta = 0.0003
lambda = 0.0001  is working -- 79.65 by epoch 16, then overfitting
[KILLED]

eta = 0.0003
lambda = 0.0003 slowly increasing -- 79.16 by epoch 25

eta = 0.0003
lambda = 0.001 very slow -- 72.15 by epoch 15
[KILLED]

eta = 0.00001
lambda = 0.0001 too slow (small learning rate) -- 67.44
[KILLED]

eta = 0.001
lambda = 0.0001 so far is working but improving slowly -- 79.03 by epoch 24

eta = 0.0001
lambda = 0.0001 slowly improving -- 79.14 by epoch 19

eta = 0.0001
lambda = 0.0003 -- very slowly improving -- 77.78 by epoch 18
[KILLED]



sparse attention
===================

eta = 0.0003
lambda = 0.0001  is overfitting now -- 79.67 by epoch 27 [starting to overfit]

eta = 0.0003
lambda = 0.0003 is slowly improving -- 78.53 by epoch 17


no attention
===================

eta = 0.0003
lambda = 0.0001  is working and still improving -- 79.04 by epoch 17 -- then overfitting 
[KILLED]

eta = 0.0003
lambda = 0.0003 is working and improving slowly -- 77.68 by epoch 17
[KILLED]


sparse attention, no jesus
===================

eta = 0.0003
lambda = 0.0001 improving slowly -- 79.79 by epoch 39, still improving

